{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Sentiment Analysis is just one part of Natural Language Processing (NLP). At its most basic level, the main idea behind sentiment analysis is to categorize a section of text (words, sentences, tweets, etc) either as \"postive\" or \"negative\". However sentiment analysis is not only limited to just \"postive\" and \"negative\", it could also categorized by different emotions. There are many different ways to conduct sentiment analysis, in this notebook we showcase a few ways to do so ranging from very basic to more advance methods.   \n",
    "\n",
    "It is important to note here we are going to avoid just matching words to calculate sentiment. That is to say, we are not going to have a dictionary of words of a category (e.x 'postive') and seeing if the input text contains those words. This is a relative simple method to calculate sentiment anaylsis. Therefore we are going to mainly focus on predicting the sentiment of a input text.\n",
    "\n",
    "In this notebook we will showcase a few way to do so.\n",
    "\n",
    "To find out more about what Sentiment Analysis is see: \n",
    " * https://en.wikipedia.org/wiki/Sentiment_analysis \n",
    " * https://www.brandwatch.com/blog/understanding-sentiment-analysis/\n",
    " \n",
    "For full installation methods used in this notebook see their respective sites. \n",
    "\n",
    "Written 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Sentiment Analysis\n",
    "\n",
    "We will first showcase a very basic method to conduct sentiment analysis. This example is not comprehensive, and is mostly shown to help demostrate the core concept of sentiment analysis, which is to train a model (program) to predict the sentiment of a body of text. \n",
    "\n",
    "We will first create some list of words that we believe are \"postive\", \"neutral\", and \"negative\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of words belonging to each category\n",
    "\n",
    "positive_words = ['good','great','awesome','happy','fun','exciting']\n",
    "neutral_words = ['any','other','words','i','believe','mean','neutral']\n",
    "negative_words = [ 'bad', 'worst','terrible','sad','angry' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these set of words we are going to train a model to help us categories different text. As you can tell, the list above is very basic and is mostly used as an example. If you have your own corpus of words for each category, feel free to use them (as long as it is in the format of the one above, if you want to keep following the example). \n",
    "\n",
    "First we will import some of the libraries we are going to use. For full installation steps see their package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required library\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined some libraries, we can move on to defining a helper function. This function will label the words as \"postive\", etc. This way when we encounter those words later, it will label them as such. This is sometimes referred to as \"word features\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for labeling our categories\n",
    "def sentiment_label(category_words):\n",
    "    return dict([(category_words, True) for word in category_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have done that we can move onto labeling each set of words we defined eariler. As you will see, the code so far allows you to expand the categories from just \"postive, negative, and neutral\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Labelling each words to their corresponding category\n",
    "positive_label_words = [(sentiment_label(positive), 'positive') for positive in positive_words]\n",
    "neutral_label_words  = [(sentiment_label(neutral), 'neutral') for neutral in neutral_words]\n",
    "negative_label_words  = [(sentiment_label(negative), 'negative') for negative in negative_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have completed all the setup required. All that is left is to train the model on our categories and test it out. Before we move on, it is important to discuss that what we are doing is to \"predictive\". It may not be accurate in all cases (dependent on your labels/features and model).\n",
    "\n",
    "We will start by setting up the classifier using the labels we created eariler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the classifier\n",
    "classifier = NaiveBayesClassifier.train((positive_label_words + neutral_label_words + negative_label_words)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to try out our classifier. To help keep things organized a function will be created to predict the sentiment of the input text. In this function you can alter it to do additional cleaning to the text or manipulate it however you wish. In this example we are simply going to split it by word and set it to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function to predict the sentiment of the input text\n",
    "def simple_predict(input_text):\n",
    "    \n",
    "    # Set all the values to 0 to start for each category\n",
    "    postive =0 \n",
    "    negative = 0 \n",
    "    neutral = 0\n",
    "    \n",
    "    # Split the input text into words and set it to lower case\n",
    "    formatted_input = input_text.lower().split(' ')\n",
    "\n",
    "    # Classify each word\n",
    "    for word in formatted_input:\n",
    "        classResult = classifier.classify(sentiment_label(word))\n",
    "\n",
    "        # Depending on the results increase the corresponding category\n",
    "        if classResult == 'positive':\n",
    "            postive = postive + 1\n",
    "        elif classResult == 'neutral':\n",
    "            neutral = neutral + 1\n",
    "        elif classResult == 'negative':\n",
    "            negative = negative + 1\n",
    "        \n",
    "    # Print out the results\n",
    "    print('Positive: ' + str(float(postive)/len(formatted_input)))\n",
    "    print('Neutral: ' + str(float(neutral)/len(formatted_input)))\n",
    "    print('Negative: ' + str(float(negative)/len(formatted_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that compeleted we can try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.2\n",
      "Neutral: 0.8\n",
      "Negative: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Testing out the predicting function\n",
    "simple_predict(\"Awesome movie, I liked it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this is not too accurate and the sentence is more postive than neutral. Therefore this inaccurate results can be attributed to the fact that our model or classifier is not trained well (limited vocabulary size, lack of cleaning, etc). \n",
    "\n",
    "In addition we can improve our results via cleaning. For example the word \"like\" and \"liked\" are the same word. Therefore you can apply stemming (or any other cleaning method) to help standardize the input text.\n",
    "\n",
    "For additional information see:\n",
    "* https://pythonspot.com/python-sentiment-analysis/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Vader \n",
    "\n",
    "Another method to conduct sentiment anaylsis is to use NLTK Vader. This is library in NLTK that can be used to calculate how positive, negative, and neutral a text is. Compared to the previous example, Vader does not require you to define what is \"positive, negative, and neutral\". Depending on your goal and purpose, this may or may not be relavent. \n",
    "\n",
    "To begin we will import Vader from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better showcase the differences between this method and the previous we will be using the exact same sentences for analysis. However before we can do that we need to declare the analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare Analyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the analyzer declared we can analysis our sentence. First we are going to calculate the score and then print it out (the print statement is formatted so it is easier to read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: 0.7845 neg: 0.0 neu: 0.225 pos: 0.775 "
     ]
    }
   ],
   "source": [
    "# Calculate sentiment score\n",
    "sentiment_Score = sid.polarity_scores(\"Awesome movie, I liked it\")\n",
    "\n",
    "# Print out the score\n",
    "for score in sorted(sentiment_Score):\n",
    "    print('{0}: {1} '.format(score, sentiment_Score[score]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, compared the the previous example Vader believes that this sentence is more postive than neutral. For those that want more control over what constitutes a \"postive\" word (etc) or would like additional categories outside the 3 presented, Vader may not be the method you want. \n",
    "\n",
    "For additional information on Vader see it documentation at:\n",
    "* http://www.nltk.org/howto/sentiment.html \n",
    "* https://www.nltk.org/_modules/nltk/sentiment/vader.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook we touched on two different methods to conduct sentiment analysis. Although this notebook does not show all the ways to conduct sentiment analysis, it does showcases some common ones. Depending on your needs, each method can be expanded and altered to fit you needs. For example, additional cleaning and larger vocabulary of words could lead to more accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
