{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Regular Expressions to Clean up Web Pages\n",
    "\n",
    "This notebook will make use of regular expressions to clean up a webpage. This is useful if you want to carry out any meaningful textual analysis of the content in a web page. We can remove the html tags and other unnecessary textual elements with this method. \n",
    "\n",
    "Regular Expressions (or Regex) is a coding technique that functions in many programming languages. Regex makes use of metacharacters (!?^.) and literal strings to carry out its operations. For a full list of Regex metacharacters and their associated functions, please see the Regex cheatsheet: http://www.rexegg.com/regex-quickstart.html\n",
    "\n",
    "## Libraries and Resources used\n",
    "\n",
    "-  Python 3\n",
    "-  re\n",
    "-  urllib\n",
    "\n",
    "Written February 27, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import re\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Content from a Website\n",
    "\n",
    "In order to start the cleaning, we need to import a site's content into python.\n",
    "For the purposes of this notebook we have used the landing page from TAPoR's companion site, Methodica. \n",
    "Feel free to use the url for any site that you wish to clean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" dir=\"ltr\"\n",
      "  xmlns:content=\"http://purl.org/rss/1.0/modules/content/\"\n",
      "  xmlns:dc=\"http://purl.org/dc/terms/\"\n",
      "  xmlns:foaf=\"http://xmlns.com/foaf/0.1/\"\n",
      "  xmlns:og=\"http://ogp.me/ns#\"\n",
      "  xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"\n",
      "  xmlns:sioc=\"http://rdfs.org/sioc/ns#\"\n",
      "  xmlns:sioct=\"http://rdfs.org/sioc/types#\"\n",
      "  xmlns:skos=\"http://www.w3.org/2004/02/skos/core#\"\n",
      "  xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\" />\n",
      "<link rel=\"shortcut icon\" href=\"http://methodi.ca/sites/all/themes/methodica_theme/favicon.ico\" type=\"image/vnd.microsoft.icon\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\" />\n",
      "<link rel=\"canonical\" href=\"/methodica\" />\n",
      "<meta name=\"Generator\" content=\"Drupal 7 (http://drupal.org)\" />\n",
      "<link rel=\"shortlink\" href=\"/node/2\" />\n",
      "<title>Welcome to the Methods Commons | Methods Commons</title>\n",
      "<style type=\"text/css\" media=\"all\">\n",
      "@import url(\"http://methodi.ca/modules/system/syst\n"
     ]
    }
   ],
   "source": [
    "# Store your url in a variable\n",
    "path = 'http://methodi.ca/' \n",
    "\n",
    "# Read in the content from the url\n",
    "with urllib.request.urlopen(path) as response:\n",
    "    webContent = response.read().decode('utf-8')\n",
    "# Print out the first 1000 characters of the content to see what kind of html tags we are dealing with\n",
    "print(webContent[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate Whitespace\n",
    "\n",
    "By examining these first 1000 characters, you may notice that there are some unnecessary lines and spaces. This 'whitespace' can be eliminated with a couple of lines of Regex. This step is also important as Regex doesn't match over newline (\\n) characters and failing to do this first will result in our code not operating as it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html> <html lang=\"en\" dir=\"ltr\"   xmlns:content=\"http://purl.org/rss/1.0/modules/content/\"   xmlns:dc=\"http://purl.org/dc/terms/\"   xmlns:foaf=\"http://xmlns.com/foaf/0.1/\"   xmlns:og=\"http://ogp.me/ns#\"   xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"   xmlns:sioc=\"http://rdfs.org/sioc/ns#\"   xmlns:sioct=\"http://rdfs.org/sioc/types#\"   xmlns:skos=\"http://www.w3.org/2004/02/skos/core#\"   xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\"> <head> <meta charset=\"utf-8\" /> <link rel=\"shortcut icon\" href=\"http://methodi.ca/sites/all/themes/methodica_theme/favicon.ico\" type=\"image/vnd.microsoft.icon\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\" /> <link rel=\"canonical\" href=\"/methodica\" /> <meta name=\"Generator\" content=\"Drupal 7 (http://drupal.org)\" /> <link rel=\"shortlink\" href=\"/node/2\" /> <title>Welcome to the Methods Commons | Methods Commons</title> <style type=\"text/css\" media=\"all\"> @import url(\"http://methodi.ca/modules/system/syst\n"
     ]
    }
   ],
   "source": [
    "# Eliminate new line characters with re.sub\n",
    "# This function works by substituting the new line character with a space\n",
    "webContent = re.sub(r'\\n', \" \", webContent)\n",
    "\n",
    "# Check the altered text\n",
    "print (webContent[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html> <html lang=\"en\" dir=\"ltr\" xmlns:content=\"http://purl.org/rss/1.0/modules/content/\" xmlns:dc=\"http://purl.org/dc/terms/\" xmlns:foaf=\"http://xmlns.com/foaf/0.1/\" xmlns:og=\"http://ogp.me/ns#\" xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:sioc=\"http://rdfs.org/sioc/ns#\" xmlns:sioct=\"http://rdfs.org/sioc/types#\" xmlns:skos=\"http://www.w3.org/2004/02/skos/core#\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\"> <head> <meta charset=\"utf-8\" /> <link rel=\"shortcut icon\" href=\"http://methodi.ca/sites/all/themes/methodica_theme/favicon.ico\" type=\"image/vnd.microsoft.icon\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\" /> <link rel=\"canonical\" href=\"/methodica\" /> <meta name=\"Generator\" content=\"Drupal 7 (http://drupal.org)\" /> <link rel=\"shortlink\" href=\"/node/2\" /> <title>Welcome to the Methods Commons | Methods Commons</title> <style type=\"text/css\" media=\"all\"> @import url(\"http://methodi.ca/modules/system/system.base.css?p2m7mv\n"
     ]
    }
   ],
   "source": [
    "# Remove all occurences of 2 or more spaces\n",
    "# To grab counts of characters in a text you can use numbers in curly brackets\n",
    "webContent = re.sub(r'\\s{2,}', \" \", webContent)\n",
    "\n",
    "# Check the altered text\n",
    "print (webContent[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate HTML Tags\n",
    "\n",
    "The first thing that is readily apparent upon printing out the content is that we are dealing with a lot of html tag nonsense. \n",
    "Let's remove these elements so we can get strictly text. \n",
    "An obvious feature of HTML tags is that they come wrapped in < >.\n",
    "The text inbetween the arrows can be stripped out with Regex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<!DOCTYPE html>', '<html lang=\"en\" dir=\"ltr\" xmlns:content=\"http://purl.org/rss/1.0/modules/content/\" xmlns:dc=\"http://purl.org/dc/terms/\" xmlns:foaf=\"http://xmlns.com/foaf/0.1/\" xmlns:og=\"http://ogp.me/ns#\" xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:sioc=\"http://rdfs.org/sioc/ns#\" xmlns:sioct=\"http://rdfs.org/sioc/types#\" xmlns:skos=\"http://www.w3.org/2004/02/skos/core#\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\">', '<head>', '<meta charset=\"utf-8\" />', '<link rel=\"shortcut icon\" href=\"http://methodi.ca/sites/all/themes/methodica_theme/favicon.ico\" type=\"image/vnd.microsoft.icon\" />', '<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\" />', '<link rel=\"canonical\" href=\"/methodica\" />', '<meta name=\"Generator\" content=\"Drupal 7 (http://drupal.org)\" />', '<link rel=\"shortlink\" href=\"/node/2\" />', '<title>']\n"
     ]
    }
   ],
   "source": [
    "# First, we are going to isolate the tag content with re.findall\n",
    "# This technique is usefull if it is perhaps the tags themselves that you want to pull from the web content\n",
    "webTags = re.findall(r'<.*?>', webContent)\n",
    "\n",
    "# Check the cleaned content\n",
    "# Note that it stores the tags in the variable as a list\n",
    "print (webTags[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Welcome to the Methods Commons | Methods Commons    @import url(\"http://methodi.ca/modules/system/system.base.css?p2m7mv\"); @import url(\"http://methodi.ca/modules/system/system.menus.css?p2m7mv\"); @import url(\"http://methodi.ca/modules/system/system.messages.css?p2m7mv\"); @import url(\"http://methodi.ca/modules/system/system.theme.css?p2m7mv\");     @import url(\"http://methodi.ca/sites/all/modules/codefilter/codefilter.css?p2m7mv\");     @import url(\"http://methodi.ca/modules/comment/comment.css?p2m7mv\"); @import url(\"http://methodi.ca/modules/field/theme/field.css?p2m7mv\"); @import url(\"http://methodi.ca/modules/node/node.css?p2m7mv\"); @import url(\"http://methodi.ca/modules/search/search.css?p2m7mv\"); @import url(\"http://methodi.ca/modules/user/user.css?p2m7mv\"); @import url(\"http://methodi.ca/sites/all/modules/views/css/views.css?p2m7mv\"); @import url(\"http://methodi.ca/sites/all/modules/ckeditor/css/ckeditor.css?p2m7mv\");     @import url(\"http://methodi.ca/sites/all/\n"
     ]
    }
   ],
   "source": [
    "# Since we are looking for just the text eliminate the HTML tags with re.sub\n",
    "# This function works by substituting the characters with a space\n",
    "webContent = re.sub(r'<.*?>', \" \", webContent)\n",
    "\n",
    "# Check the cleaned content\n",
    "print (webContent[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Eliminate Additional Web Scripting\n",
    "\n",
    "Some of the text is starting to make its way to the surface, but our content is still riddled with web scripting elements. \n",
    "This is going to vary from webpage to webpage, so what I am going to provide you with here is an example of how to deal with this issue. \n",
    "A good way to begin cutting out unnecessary code is to isolate that code for your Regex expression.\n",
    "In this case, everything between and including  @import url(\".......\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Welcome to the Methods Commons | Methods Commons                                                                                                                                         Search form     Search                                  Home     Recipes     Tutorials     Examples     Utilities     Backgrounders     Glossary     About                                 Learn how to identify the locations named in a corpus and generate a map of the results.                 Work through an example of how to identify themes in a text.                 Read up on the history of text analysis tools.                              Welcome to the Methods Commons                         Methodica is a collection of research methods and techniques for analyzing text. Computation has produced new and exciting ways of studying text in the Digital Humanities, and many of these methods do not require the use of expensive programs or detailed programming knowledge. This site describes common or interesting sequences of actions, or  recipes , showing users how to combine freely accessible resources to perform various analytic tasks. Each recipe begins by listing required ingredients (text analysis tools, pieces of code, texts in certain formats, etc.), walks the user through the steps of a process, and concludes with links to further information and additional steps the researcher can try out. Methodica is a companion to the Text Analysis Portal for Research ( TAPoR)  tool repository.                                     User login         Username  *          Password  *           Request new password                        Latest Recipes           Document Clustering by Topic using K-Means and MDS   Multidimensional Scaling (MDS) is a method to convert sets of document terms into a data frame that can then be visualized....      Document Clustering by Topic using K-Means and PCA   Principal Component Analysis (PCA) is a method to convert sets of document terms into a data frame that can then be visualized...      Finding Locations in a Text Using Named-Entity Recognition in NLTK   Similar to finding  People and...      Topic Modelling to Identify Themes   In this recipe we use 3 ebooks to show how topic analysis can identify the different topics each text represents. We will use...      Word Frequency and Count of a Set of Documents   Word frequencies and counts are text analysis methods that return results about the words in a text or set of texts.  ...                Random Term        Glasgow Stop Words list      The Glasgow Stop Words list is a popular Stop list developed by the Information Retrieval Group at the University of Glasgow. The TAPoR and Voyant toolsets use a modified version of the Glasgow Stop Words list in their respective text analysis tools. The modifications include the addition of numeric characters, punctuation, other text symbols, individual letters, and the removal of words such as 'top', 'sincere' and 'beyond'. This list may be applied or ignored according to the needs of the user: for example, a search for common phrases may wish to retain the stop words in the results, while a search for the top words may wish to filter them out.   Visit the Glossary                             Copyright &copy; 2018,  University of Alberta    Theme by the Methodica Team  Methodica Team   -->          \n"
     ]
    }
   ],
   "source": [
    "# Use the same substitution technique to remove the unnecessary code\n",
    "webContent = re.sub(r'@import url.*?;', \" \", webContent)\n",
    "\n",
    "# Check the cleaned content\n",
    "print (webContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Welcome to the Methods Commons | Methods Commons                                                                                                                                         Search form     Search                                  Home     Recipes     Tutorials     Examples     Utilities     Backgrounders     Glossary     About                                 Learn how to identify the locations named in a corpus and generate a map of the results.                 Work through an example of how to identify themes in a text.                 Read up on the history of text analysis tools.                              Welcome to the Methods Commons                         Methodica is a collection of research methods and techniques for analyzing text. Computation has produced new and exciting ways of studying text in the Digital Humanities, and many of these methods do not require the use of expensive programs or detailed programming knowledge. This site describes common or interesting sequences of actions, or  recipes , showing users how to combine freely accessible resources to perform various analytic tasks. Each recipe begins by listing required ingredients (text analysis tools, pieces of code, texts in certain formats, etc.), walks the user through the steps of a process, and concludes with links to further information and additional steps the researcher can try out. Methodica is a companion to the Text Analysis Portal for Research ( TAPoR)  tool repository.                                     User login         Username  *          Password  *           Request new password                        Latest Recipes           Document Clustering by Topic using K-Means and MDS   Multidimensional Scaling (MDS) is a method to convert sets of document terms into a data frame that can then be visualized....      Document Clustering by Topic using K-Means and PCA   Principal Component Analysis (PCA) is a method to convert sets of document terms into a data frame that can then be visualized...      Finding Locations in a Text Using Named-Entity Recognition in NLTK   Similar to finding  People and...      Topic Modelling to Identify Themes   In this recipe we use 3 ebooks to show how topic analysis can identify the different topics each text represents. We will use...      Word Frequency and Count of a Set of Documents   Word frequencies and counts are text analysis methods that return results about the words in a text or set of texts.  ...                Random Term        Glasgow Stop Words list      The Glasgow Stop Words list is a popular Stop list developed by the Information Retrieval Group at the University of Glasgow. The TAPoR and Voyant toolsets use a modified version of the Glasgow Stop Words list in their respective text analysis tools. The modifications include the addition of numeric characters, punctuation, other text symbols, individual letters, and the removal of words such as 'top', 'sincere' and 'beyond'. This list may be applied or ignored according to the needs of the user: for example, a search for common phrases may wish to retain the stop words in the results, while a search for the top words may wish to filter them out.   Visit the Glossary                             Copyright   2018,  University of Alberta    Theme by the Methodica Team  Methodica Team   -->          \n"
     ]
    }
   ],
   "source": [
    "# We are not done yet. There is some link code that needs to be eliminated \n",
    "# Use the same substitution technique to remove the unnecessary code\n",
    "webContent = re.sub(r'&.*?;', \" \", webContent)\n",
    "\n",
    "# Check the cleaned content\n",
    "print (webContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to the Methods Commons | Methods Commons Search form Search Home Recipes Tutorials Examples Utilities Backgrounders Glossary About Learn how to identify the locations named in a corpus and generate a map of the results. Work through an example of how to identify themes in a text. Read up on the history of text analysis tools. Welcome to the Methods Commons Methodica is a collection of research methods and techniques for analyzing text. Computation has produced new and exciting ways of studying text in the Digital Humanities, and many of these methods do not require the use of expensive programs or detailed programming knowledge. This site describes common or interesting sequences of actions, or recipes , showing users how to combine freely accessible resources to perform various analytic tasks. Each recipe begins by listing required ingredients (text analysis tools, pieces of code, texts in certain formats, etc.), walks the user through the steps of a process, and concludes with links to further information and additional steps the researcher can try out. Methodica is a companion to the Text Analysis Portal for Research ( TAPoR) tool repository. User login Username * Password * Request new password Latest Recipes Document Clustering by Topic using K-Means and MDS Multidimensional Scaling (MDS) is a method to convert sets of document terms into a data frame that can then be visualized.... Document Clustering by Topic using K-Means and PCA Principal Component Analysis (PCA) is a method to convert sets of document terms into a data frame that can then be visualized... Finding Locations in a Text Using Named-Entity Recognition in NLTK Similar to finding People and... Topic Modelling to Identify Themes In this recipe we use 3 ebooks to show how topic analysis can identify the different topics each text represents. We will use... Word Frequency and Count of a Set of Documents Word frequencies and counts are text analysis methods that return results about the words in a text or set of texts. ... Random Term Glasgow Stop Words list The Glasgow Stop Words list is a popular Stop list developed by the Information Retrieval Group at the University of Glasgow. The TAPoR and Voyant toolsets use a modified version of the Glasgow Stop Words list in their respective text analysis tools. The modifications include the addition of numeric characters, punctuation, other text symbols, individual letters, and the removal of words such as 'top', 'sincere' and 'beyond'. This list may be applied or ignored according to the needs of the user: for example, a search for common phrases may wish to retain the stop words in the results, while a search for the top words may wish to filter them out. Visit the Glossary Copyright 2018, University of Alberta Theme by the Methodica Team Methodica Team --> \n"
     ]
    }
   ],
   "source": [
    "# Let's run our cleaning Regex code one more time, to tighten up the text\n",
    "webContent = re.sub(r'\\n', \" \", webContent)\n",
    "\n",
    "webContent = re.sub(r'\\s{2,}', \" \", webContent)\n",
    "\n",
    "# Check the altered text\n",
    "print (webContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "Importing sites into Python also brings in all of the additional HTML elements that may get in the way of any textual analyisis we need to do on the web content. Regex is a fairly simple way to eliminate those elements. We can even use it to isolate certain tags and lines of code that we might need for our project. The Regex required for cleaning is going to change from site to site, so this notebook should be taken more as an example and not as a strict set of instructions on how to do so. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
