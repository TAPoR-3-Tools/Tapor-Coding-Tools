{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK for Named Entity Recognition (Location)\n",
    "\n",
    "Using NLTK library to extract locations from a text file and geotext library goes further to extract nationalities, cities and countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eisenstein was born to a middle-class family in Riga, Latvia (then part of the Russian Empire in the Governorate of Livonia), but his family moved frequently in his early years, as Eisenstein continued to do throughout his life. His father, Mikhail Osipovich Eisenstein, was born to a German Jewish father who had converted to Christianity, Osip Eisenstein, and a mother of Swedish descent. His mother, Julia Ivanovna Konetskaya, was from a Russian Orthodox family. According to other sources, both of his paternal grandparents were of Baltic German descent. His father was an architect and his mother was the daughter of a prosperous merchant. Julia left Riga the same year as the Russian Revolution of 1905, taking Sergei with her to St. Petersburg. Her son would return at times to see his father, who joined them around 1910. Divorce followed and Julia left the family to live in France. Eisenstein was raised as an Orthodox Christian, but became an atheist later on.\n"
     ]
    }
   ],
   "source": [
    "with open(\"NE.txt\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "- First, we will split the text into sentences using a sentence segmenter `nltk.sent_tokenize`\n",
    "- Each sentence will be further sibdivided into words using a word tokenizer `nltk.word_tokenize`\n",
    "- Next, each sentence will be tagged with part-of-speech tags using `nltk.pos_tag`, which will prove very helppful in the next step, name entity detection.\n",
    "- Next is to chunk the tagged sentences using `nltk.ne_chunk`. Chunking aims at grouping elements of the sequence, without any differentiation between obtained groups. For example, noun phrase chunking or verb group chunking.\n",
    "- After chunking, named entities will be labeld as \"GPE\" if the chunk is a location name.\n",
    "\n",
    "\n",
    "The following code can easily realize the steps listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Riga',\n",
      " 'Latvia',\n",
      " 'Russian',\n",
      " 'Livonia',\n",
      " 'German',\n",
      " 'Christianity',\n",
      " 'Swedish',\n",
      " 'Russian',\n",
      " 'Baltic',\n",
      " 'German',\n",
      " 'Russian',\n",
      " 'St. Petersburg',\n",
      " 'France']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from pprint import pprint\n",
    "\n",
    "# create a list to store location names\n",
    "loc_names = []\n",
    "\n",
    "# tokenize sentences\n",
    "for sentence in nltk.sent_tokenize(text):\n",
    "    # tokenize words in each sentence\n",
    "    word_tokens = nltk.word_tokenize(sentence)\n",
    "    # words tagged with part-of-speech tags\n",
    "    tagged_words = nltk.pos_tag(word_tokens)\n",
    "    # then chunk the related words\n",
    "    for chunk in nltk.ne_chunk(tagged_words):\n",
    "        if hasattr(chunk, 'label') and chunk.label()=='GPE':\n",
    "            loc = ' '.join(leave[0] for leave in chunk.leaves())\n",
    "            loc_names.append(loc)\n",
    "\n",
    "pprint(loc_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using geotext package for location extraction\n",
    "[Geotext](https://pypi.python.org/pypi/geotext) is a python package helps to extracts countriy and city mentions from text.\n",
    "#### Install geotext library\n",
    "First, we need to install geotext. Type the following command in the terminal and press enter to install:\n",
    "    \n",
    "    pip install geotext\n",
    "\n",
    "On Jupyter, you can install directly on the notebook by prepending an exclamation mark on the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geotext in /home/anthony/anaconda3/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install geotext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use our text to have a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Swedish']\n",
      "['Latvia', 'France']\n",
      "['Riga', 'Livonia', 'Riga', 'Petersburg']\n"
     ]
    }
   ],
   "source": [
    "from geotext import GeoText\n",
    "\n",
    "places = GeoText(text)\n",
    "print(places.nationalities)\n",
    "print(places.countries)\n",
    "print(places.cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
